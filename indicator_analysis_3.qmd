---
title: "Initial Indicator Analysis"
author: "William Becker"
format: html
toc: true
---

## Intro

This is a short document to record the initial indicator analysis of the Municipal Vulnerability Index (MVI) for Guatemala.

The objectives here are:

1. Univariate analysis based on data availability, uniqueness, distribution properties.
2. Multivariate analysis based on correlations.

We recall that the end objective here is to eventually arrive at a "module" which can be used for selecting indicators based on statistical characteristics. Therefore we need some basic criteria to do that by.

Typical criteria for indicator selection and treatment can be as follows:

- Percentage missing data (indicators below a set percentage are flagged - this is often set at e.g. 66%)
- Percentage zeroes (indicators above a set percentage are flagged - this could be e.g. 50%)
- Percentage unique values (again, we can set a threshold here)
- Presence of outliers, flagged by having both |skew| > 2 and kurtosis > 3.5
- Collinearity with other indicators in the same aggregation group
- Strong negative correlation with other indicators in the same group

The idea here would be to simply flag these things to the user, who then has the option to either remove or retain the indicators.

## Data import

In a previous version, I began cleaning and formatting the data directly in R. However, since the end objective is to arrive at data modules that can deal with data from other countries, we need to consider a generic input format and it makes sense to do this early on.

So for now I have an intermediate solution, which is to format the data in Excel for COINr. I have also sketched out a possible generic format based on one sheet. However this latter will need the structure of the index hard-coded in the end product, so I'm going to begin by importing the familiar `iData` and `iMeta` data frames.

What I did in Excel:

* Extracted the indicator data, keeping only column headers (codes) and renaming the municipal code to `uCode` and the Municipio to `uName`.
* Created short codes for aggregate levels
* Created an `imeta` table based on the indicator metadata table from the master sheet. This renames columns, converts some things to COINr-compatible (e.g. directions), and also adds the rows for the aggregate levels which effectively defines the structure of the index.
* I noticed one probable typo/mistake and corrected. In the indicator data the code for "Tasa de Pobreza" is "S.E.3" whereas in the metadata it is specified as "S.E.4". I altered the latter to "S.E.3" as I presume this is what it should be.

A suggestion here would be that for any new indicators that become available, we could directly add them to the `iData` table. We could potentially have an Excel sheet with reads the master indicator table and formats it for import to R.

We begin by importing the data set as it stands (the version at the time of writing is 30/01/2023).

```{r}
library(readxl)

# note: if indicators are added the ranges here will need to be adjusted
idata <- read_excel("data_input/data_input_formatted.xlsx", sheet = "iData")
imeta <- read_excel("data_input/data_input_formatted.xlsx", sheet = "iMeta")

idata
```

The data includes columns of indicator data, but also municipal code, name of municipality, and department code and name. Now also the main ID for each row is the "admin2Pcode" which are standardised second-level subnational codes used by UNHCR. We just have to rename this column to be called `uCode` so it is recognised by COINr.

```{r}
names(idata)[names(idata) =="admin2Pcode"] <- "uCode"
```

It is also evident that some indicators here are placeholders and have no available data yet. We have to remove these first.

```{r}
# which indicators have no data?
i_nodata <- names(idata)[colSums(!is.na(idata)) == 0]
i_nodata

idata <- idata[!(names(idata) %in% i_nodata)]
```

With this, the `idata` data frame is in the correct format. As for the metadata `imeta`, this has already been formatted in Excel. The only thing to note here is that I have removed some metadata columns which are not necessary for COINr. If needed, we could pass through other columns in the future.

The last thing to do is to check consistency between `imeta` and `idata`. Since we removed columns from `idata` we also have to remove these from `imeta`.

```{r}
imeta <- imeta[!(imeta$iCode %in% i_nodata), ]
```

Check whether all `imeta` codes are in `idata`:

```{r}
# exclude aggregate rows
imeta_i <- imeta[imeta$Type != "Aggregate", ]

# any codes missing?
missing_idata <- imeta_i$iCode[!(imeta_i$iCode %in% names(idata))]
missing_idata
```
This is fine. Now do the reverse check:

```{r}
icodes_idata <- names(idata)[!(names(idata) %in% c("uCode", "uName"))]

icodes_idata[!(icodes_idata %in% imeta$iCode)]
```

OK so everything looks consistent. There is one last thing I found which causes a problem. One of the categories "Acc_Hum" doesn't have any indicators underneath it with any data so we need to remove it.

```{r}
imeta <- imeta[!(imeta$iCode %in% c("Acc_Hum")), ]
```



This means that now we can go ahead and enter the data into COINr, and assemble a "coin". We will also clean up the environment.

```{r}
library(COINr)

MVI <- new_coin(iData = idata, iMeta = imeta, level_names = c("Indicator", "Category", "Dimension", "Index"))

# clean all except coin
rm(list = setdiff(ls(), "MVI"))
```

## Analysis

With the data in COINr we can begin the analysis. The first thing is to look at the structure of the index:

```{r}
#| fig-width: 12
#| fig-height: 10
plot_framework(MVI, type = "stack", text_size = 4)
```

Let us also check the contents of the coin:

```{r}
MVI
```

In previous versions of this analysis, we experimented with denominating indicators inside COINr. After some reflection we decided instead to do denomination before the data enters R, so at this point all indicators are denominated. This means that the analysis can be performed directly on the raw data.

We can quickly generate a table of indicator statistics in COINr using the `get_stats()` function, and this will help us with several of the analysis tasks.

```{r}
df_stats <- get_stats(MVI, dset = "Raw",
                      t_skew = 2, t_kurt = 3.5,
                      t_avail = 0.66,
                      t_zero = 0.66,
                      t_unq = 0.5,
                      out2 = "df")
```

### Data availability

Let's begin with data availability. Let's assume a rule "data availability should be greater than or equal to 66%". Under this criterion let's see which indicators are flagged:

```{r}
df_stats[df_stats$Flag.Avail == "LOW", c("iCode", "N.Avail", "Frc.Avail")]
```

This shows that no indicators are flagged. In a previous version of this analysis one indicator did have low data and this has since been removed, so now all indicators have a good data availability. We can in fact check the lowest data availability indicators:

```{r}
library(dplyr)

df_stats |>
  select(iCode, N.Avail, Frc.Avail) |>
  arrange(Frc.Avail) |>
  head(5) |>
  knitr::kable(row.names = F)
```

This shows that the data availability is in general very high.

### Zeros and duplicates

Zeros are not a problem per se, but quite often we find indicators with a very large proportion of zeros and just a handful of non-zero values. Or more generally we find that a large proportion of indicator values share the same value. This means that the power of the indicator to differentiate between units/regions is quite low. We can check this using the stats table.

```{r}
df_stats[(df_stats$Frc.NonZero < 0.5) | (df_stats$Frc.Same > 0.5), c("iCode", "Frc.NonZero", "Frc.Same")]
```

Here the indicators "A.M.1" ("# de personas refugiadas y solicitantes de asilo") and "C.J.2" ("Tasa de establecimientos de justicia por 100.000 habitantes) are flagged. This is because respectively 75% and 70% of the indicator values are duplicates:

```{r}
#| warning: false
#| message: false
plot_dist(MVI, dset = "Raw", iCodes = c("A.M.1", "C.J.2"), type = "Dot")
```

These indicators have a low power to differentiate between municipalities, which makes them less useful but can still be retained if important to the framework.

### Outliers

In composite indicator construction, a rule of thumb to identify distributions with outliers is any distributions that have absolute skew greater than 2 and kurtosis greater than 3.5. This is very much subjective but gives a rough idea and usually helps flag distributions that warrant a closer look. As for why we should be concerned about outliers at all, see my opinions [here](https://bluefoxr.github.io/COINrDoc/data-treatment.html#why-treat-data).

In any case let's see which indicators are flagged on this basis:

```{r}
df_outliers <- df_stats[df_stats$Flag.SkewKurt == "OUT", c("iCode", "Skew", "Kurt")]
knitr::kable(df_outliers, row.names = F)
```

There are a total of 17 indicators flagged. This deserves a closer look. I'll plot in groups of six

```{r}
plot_dist(MVI, dset = "Raw", iCodes = df_outliers$iCode[1:6])
plot_dist(MVI, dset = "Raw", iCodes = df_outliers$iCode[7:12])
plot_dist(MVI, dset = "Raw", iCodes = df_outliers$iCode[13:17])
```

The plots here are all fairly similar and reflect log-normal distributions. We already know that most indicators have a reasonable proportion of unique values, so the high skew/kurtosis values are not caused by duplications. These are typical distributions that are associated with socioeconomic variables such as GDP, wealth, and so on (heavily skewed).

These indicators are not problematic but may need a data transformation, depending on the objectives of the index (to be discussed). The default here would be to apply a log transformation to each indicator before aggregation, which would make the distributions roughly normal.

### Correlations

Here we look at the associations between indicators, using correlations. Although correlations are a linear measure of dependence and relationships could be nonlinear, linear dependence still does a good job of flagging strong associations which we can later check more closely if required.

Let us begin with a general plot of all correlations between indicators to get an idea for the correlation structure. We exclude correlations between indicators that are not in the same dimension, and we draw boxes around each categoria. We also account for the *directions* of indicators, i.e. indicators with negative directionality have their directions reversed before calculating correlations.

```{r}
plot_corr(MVI, dset = "Raw", showvals = FALSE, box_level = 2,
          grouplev = 3, flagcolours = TRUE, cortype = "spearman", pval = 0, use_directions = TRUE)
```

This shows that in the most correlations except within the "Situación socioeconómica" dimension can be considered "OK" (correlation 0.3-0.9) or "weak" (correlation between -0.4 and 0.3). Obviously these thresholds are rough. In any case the main things to look out for are strongly negative correlations (which almost cancel out in aggregation) or collinearities (which can imply double counting). COINr has a dedicated function for picking these up:

```{r}
# any correlations above 0.9 within the same categoria
neg_corrs <- get_corr_flags(MVI, dset = "Raw", cor_thresh = 0.9, thresh_type = "high",
               grouplev = 2, cortype = "spearman", use_directions = TRUE)

if(nrow(neg_corrs) > 0){
  knitr::kable(neg_corrs, row.names = F)
}
```

Here there are no collinear indicators within the first level of aggregation (categorias).

We can do the same for negative correlations:

```{r}
# any negative correlations below -0.4 within the same categoria
get_corr_flags(MVI, dset = "Raw", cor_thresh = -0.4, thresh_type = "low",
               grouplev = 2, cortype = "spearman", use_directions = TRUE) |>
  knitr::kable(row.names = F)
```

Here we see one strong negative correlation in particular. We will visualise the two strongest correlation pairs:

```{r}
#| warning: false
p1 <- plot_scatter(MVI, dsets = "Raw", iCodes = c("S.G.3", "S.G.4"), log_scale = c(F, T))
p2 <- plot_scatter(MVI, dsets = "Raw", iCodes = c("S.G.3", "S.G.8"))

library(patchwork)
p1 + p2
```

The negative correlation of S.G.3 against S.G.4 is only moderate and, although not ideal, does not give a strong case for removing any of these indicators unless there are additional reasons to do so. The plot of S.G.3 against S.G.8 is of particular interest: it seems that where there are a lot of Maya people there are very few ladino/mestizo people. I wonder however if this is an artifact of the way one of these indicators is calculated - perhaps one is calculated based on the other?

## Conclusions

This analysis has checked:

* Data availability
* Zeroes and duplicates
* Outliers
* Presence of collinearity and/or strong negative correlations within groups

The objective being to see if indicators are *statistically* suitable for inclusion into the index. This makes no consideration of *conceptual* matters such as whether each indicator is relevant to the concept of vulnerability at the municipal level.

At this point the analysis has been through several iterations and most issues have been addressed. Perhaps the only issue to still keep in mind is the strange relationship between  S.G.3 and S.G.8.
  
### Summary table

Looking ahead to semi-automating the process that we went through above, we could consider a summary table which automatically generates the kind of "flags" in one shot that were brought up in the analysis. The table below is generated by the `get_indicator_flags()` function which summarises any indicators that have any of low data availability, a high number of "same" indicators, have outliers, and collinear or negative correlations within the same categoria. 

```{r}
source("R/selection.R")
source("R/table_tests.R")

l_flags <- get_indicator_flags(MVI, "Raw")

# adjust for table
l_flags$df_flag$iCode <- FALSE

highlight_DT(l_flags$df_disp, l_flags$df_flag)
```

The table automatically highlights any cells where a threshold is exceeded and the indicator is flagged.
