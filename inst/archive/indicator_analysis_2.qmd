---
title: "Initial Indicator Analysis"
author: "William Becker"
format: html
toc: true
---

## Intro

This is a short document to record the initial indicator analysis of the Municipal Vulnerability Index (MVI) for Guatemala.

The objectives here are:

1. Univariate analysis based on data availability, uniqueness, distribution properties.
2. Multivariate analysis based on correlations.

We recall that the end objective here is to eventually arrive at a "module" which can be used for selecting indicators based on statistical characteristics. Therefore we need some basic criteria to do that by.

Typical criteria for indicator selection and treatment can be as follows:

- Percentage missing data (indicators below a set percentage are flagged - this is often set at e.g. 66%)
- Percentage zeroes (indicators above a set percentage are flagged - this could be e.g. 50%)
- Percentage unique values (again, we can set a threshold here)
- Presence of outliers, flagged by having both |skew| > 2 and kurtosis > 3.5
- Collinearity with other indicators in the same aggregation group
- Strong negative correlation with other indicators in the same group

The idea here would be to simply flag these things to the user, who then has the option to either remove or retain the indicators.

## Data import

In a previous version, I began cleaning and formatting the data directly in R. However, since the end objective is to arrive at data modules that can deal with data from other countries, we need to consider a generic input format and it makes sense to do this early on.

So for now I have an intermediate solution, which is to format the data in Excel for COINr. I have also sketched out a possible generic format based on one sheet. However this latter will need the structure of the index hard-coded in the end product, so I'm going to begin by importing the familiar `iData` and `iMeta` data frames.

What I did in Excel:

* Extracted the indicator data, keeping only column headers (codes) and renaming the municipal code to `uCode` and the Municipio to `uName`.
* Created short codes for aggregate levels
* Created an `imeta` table based on the indicator metadata table from the master sheet. This renames columns, converts some things to COINr-compatible (e.g. directions), and also adds the rows for the aggregate levels which effectively defines the structure of the index.
* I noticed one probable typo/mistake and corrected. In the indicator data the code for "Tasa de Pobreza" is "S.E.3" whereas in the metadata it is specified as "S.E.4". I altered the latter to "S.E.3" as I presume this is what it should be.

A suggestion here would be that for any new indicators that become available, we could directly add them to the `iData` table. We could potentially have an Excel sheet with reads the master indicator table and formats it for import to R.

We begin by importing the data set as it stands (the version at the time of writing is 30/01/2023).

```{r}
library(readxl)

# note: if indicators are added the ranges here will need to be adjusted
idata <- read_excel(here::here("data_input","data_input_formatted.xlsx"), sheet = "iData")
imeta <- read_excel(here::here("data_input","data_input_formatted.xlsx"), sheet = "iMeta")

idata
```

The data includes columns of indicator data, but also municipal code, name of municipality, and department code and name. I have already renamed the relevant columns to the required `uCode` and `uName`. The department name and code are treated as grouping variables.

We still have a couple of things to do: one is to make the `uCode` column into a character vector that cannot be coerced to numeric.

```{r}
# we have to make iCode non-numeric
idata$uCode <- paste0("c", idata$uCode)
```

It is also evident that some indicators here are placeholders and have no available data yet. We have to remove these first.

```{r}
# which indicators have no data?
i_nodata <- names(idata)[colSums(!is.na(idata)) == 0]
i_nodata

idata <- idata[!(names(idata) %in% i_nodata)]
```

We will also do one more thing, which is to convert population columns to thousands - this avoids very small numbers generated by dividing indicators by large numbers.

```{r}
pop_cols <- startsWith(names(idata), "Pop_")

# div by 1000
idata[, pop_cols] <- idata[, pop_cols]/1000
# edit units in imeta
imeta$Unit[startsWith(imeta$iCode, "Pop_")] <- "Thousands"
```


With this, the `idata` data frame is in the correct format. As for the metadata `imeta`, this has already been formatted in Excel. The only thing to note here is that I have removed some metadata columns which are not necessary for COINr. If needed, we could pass through other columns in the future.

The last thing to do is to check consistency between `imeta` and `idata`. Since we removed columns from `idata` we also have to remove these from `imeta`.

```{r}
imeta <- imeta[!(imeta$iCode %in% i_nodata), ]
```

Check whether all `imeta` codes are in `idata`:

```{r}
# exclude aggregate rows
imeta_i <- imeta[imeta$Type != "Aggregate", ]

# any codes missing?
missing_idata <- imeta_i$iCode[!(imeta_i$iCode %in% names(idata))]
missing_idata
```
This is fine. Now do the reverse check:

```{r}
icodes_idata <- names(idata)[!(names(idata) %in% c("uCode", "uName"))]

icodes_idata[!(icodes_idata %in% imeta$iCode)]
```

OK so everything looks consistent. There is one last thing I found which causes a problem. One of the categories "Desplazamento" doesn't have any indicators underneath it so we need to remove it. And, since this is the only categoria in the "Mov_Hum" dimension, that dimension also has to be removed.

```{r}
imeta <- imeta[!(imeta$iCode %in% c("Desplaz", "Mov_Hum")), ]
```



This means that now we can go ahead and enter the data into COINr, and assemble a "coin". We will also clean up the environment.

```{r}
library(COINr)

MVI <- new_coin(iData = idata, iMeta = imeta, level_names = c("Indicator", "Category", "Dimension", "Index"))

# clean all except coin
rm(list = setdiff(ls(), "MVI"))
```

## Analysis

With the data in COINr we can begin the analysis. The first thing is to look at the structure of the index:

```{r}
#| fig-width: 12
#| fig-height: 10
plot_framework(MVI, type = "stack", text_size = 4)
```

Let us also check the contents of the coin:

```{r}
MVI
```

This looks fine. Now, the next thing is to begin with the indicator analysis. Here, the question is whether to perform the analysis on the data before or after indicators have been denominated (divided by scaling variables such as population). On reflection the sensible option seems to be to do analysis on the data *after* denomination because this is how we would expect the data to arrive in the generalised version. So, let's go ahead and denominate.

```{r}
MVI <- Denominate(MVI, dset = "Raw")
```

We don't need to specify anything here in particular because the denominator variables (populations by group) are already input with `iData`, and the mapping of which denominators to use with which indicators is specified in `iMeta`. The output is a new data set with denominated data.

We can quickly generate a table of indicator statistics in COINr using the `get_stats()` function, and this will help us with several of the analysis tasks.

```{r}
df_stats <- get_stats(MVI, dset = "Denominated",
                      t_skew = 2, t_kurt = 3.5,
                      t_avail = 0.66,
                      t_zero = 0.66,
                      t_unq = 0.5,
                      out2 = "df")
```

### Data availability

Let's begin with data availability. Let's assume a rule "data availability should be greater than or equal to 66%". Under this criterion let's see which indicators are flagged:

```{r}
df_stats[df_stats$Flag.Avail == "LOW", c("iCode", "N.Avail", "Frc.Avail")]
```

This shows that only one indicator fails: "A.M.3" which is "# de NNA no acompaÃ±ados deportados". Here, the recommendation would be to exclude this indicator since its data availability is very low, at 12%. Only if the indicator is conceptually vital should we include it.

### Zeros and duplicates

Zeros are not a problem per se, but quite often we find indicators with a very large proportion of zeros and just a handful of non-zero values. Or more generally we find that a large proportion of indicator values share the same value. This means that the power of the indicator to differentiate between units/regions is quite low. We can check this using the stats table.

```{r}
df_stats[(df_stats$Frc.NonZero < 0.5) | (df_stats$Frc.Same > 0.5), c("iCode", "Frc.NonZero", "Frc.Same")]
```

Here the indicator "A.M.1" is flagged ("# de personas refugiadas y solicitantes de asilo"). This is because 75% percent of its indicator values are zero and this can be confirmed visually:

```{r}
#| warning: false
#| message: false
plot_dist(MVI, dset = "Denominated", iCodes = "A.M.1", type = "Dot")
```

Whereas a very low data availability is a strong reason to exclude an indicator, here the flag is "weaker": this indicator has a low power to differentiate between municipalities, so is not hugely useful but if it is important to the framework it could be kept without causing any trouble.

### Outliers

In composite indicator construction, a rule of thumb to identify distributions with outliers is any distributions that have absolute skew greater than 2 and kurtosis greater than 3.5. This is very much subjective but gives a rough idea and usually helps flag distributions that warrant a closer look. As for why we should be concerned about outliers at all, see my opinions [here](https://bluefoxr.github.io/COINrDoc/data-treatment.html#why-treat-data).

In any case let's see which indicators are flagged on this basis:

```{r}
df_outliers <- df_stats[df_stats$Flag.SkewKurt == "OUT", c("iCode", "Skew", "Kurt")]
knitr::kable(df_outliers, row.names = F)
```

There are a total of 20 indicators flagged, which is quite a lot. This deserves a closer look. I'll plot in groups of eight

```{r}
plot_dist(MVI, dset = "Denominated", iCodes = df_outliers$iCode[1:8])
plot_dist(MVI, dset = "Denominated", iCodes = df_outliers$iCode[9:16])
plot_dist(MVI, dset = "Denominated", iCodes = df_outliers$iCode[17:20])
```

The plots here are all fairly similar and reflect log-normal distributions. We already know that most indicators have a reasonable proportion of unique values, so the high skew/kurtosis values are not caused by duplications. These are typical distributions that are associated with socioeconomic variables such as GDP, wealth, and so on (heavily skewed).

These indicators are not problematic but may need a data transformation, depending on the objectives of the index (to be discussed). The default here would be to apply a log transformation to each indicator before aggregation, which would make the distributions roughly normal.

### Denominators

In this section we can briefly check for any unintended issues regarding denominators. "Denominators" are variables that are used to scale indicators so that municipalities of different sizes can be compared fairly. A typical example is dividing GDP by population to get GDP/capita, which can be used as a meaningful comparison of wealth between countries of different sizes.

The indicators in the MVI have been denominated earlier in this analysis. Although denomination is a conceptual task, we can also get hints of potential issues via correlations. Specifically, we check for high correlations between indicators and any of the denominators. This will become clear by running the relevant COINr function:

```{r}
get_denom_corr(MVI, dset = "Denominated", cor_thresh = 0.8, cortype = "spearman") |>
  knitr::kable(row.names = F)
```

The above table shows any high correlations between indicators and denominators (absolute value above 0.8) *after* the indicators have passed through the denomination stage. Here we can see some things to check.

The indicator "C.E.10" has very high correlations with population indicators (since all are variations of populations we take this to mean it is correlated with population). This is interesting because it was *already* divided by "Pop_NNA" - so what does it mean? In this case, it means that perhaps "C.E.10" should not have been divided by population.

From a statistical point of view, we divide an indicator by a denominator because *before* denomination it has a strong association with that denominator. By dividing it, we make it (mostly) independent of that denominator, which is in fact the objective (making indicators size-independent, or *intensive*). Now, if an indicator is *not* related to an denominator, and we divide by that denominator, what happens? Then it becomes strongly dependent on it! And I think this what has happened here.

In short, "C.E.10" was not related to population. Since it was divided by population, now it is related (negatively) to population. We can check

```{r}
p1 <- plot_scatter(MVI, dsets = c("Raw", "uMeta"), iCodes = c("C.E.10", "Pop_NNA"), log_scale = c(FALSE, TRUE))
p2 <- plot_scatter(MVI, dsets = c("Denominated", "uMeta"), iCodes = c("C.E.10", "Pop_NNA"), log_scale = c(TRUE, TRUE))

library(patchwork)
p1 + p2
```

Also on a conceptual level, the indicator is "# de alumnos por docente en todos los niveles" which should not be related to population since it is a ratio of pupils to teachers.

Let's also check the others. First, "C.I.7" which is "% de la poblaciÃ³n cubierta con servicios de agua y saneamiento" which was *not* denominated by anything. We can produce before and after plots as before:

```{r}
plot_scatter(MVI, dsets = c("Denominated", "uMeta"), iCodes = c("C.I.7", "Pop_Total"), log_scale = c(TRUE, TRUE))
```

This shows that this indicator has a strong association with total population, and therefore could be considered for denomination. Supposedly, this indicator measures the percentage of population covered by water/sanitation services. But, this is strange because as the figure shows above, its values lie well outside of the expected 0-100 range if it were a percentage! So this needs to be carefully checked.

This also points to the need to review carefully the meaning of each indicator before proceeding. I also notice that other indicators that are described as percentages have values that are not in a percentage range.

Another indicator that is in the flagged list above is "S.G.1" and this looks like it may have the same issue. It is described as "% de personas con discapacidad" and has no denominator assigned. Let's plot it as previously.

```{r}
plot_scatter(MVI, dsets = c("Denominated", "uMeta"), iCodes = c("S.G.1", "Pop_Total"), log_scale = c(TRUE, TRUE))
```

We see a similar pattern: this is strongly related to population, and also its values look like population *numbers*, not percentages. This is also true for the other indicator flagged, "S.G.7". In fact, all "S.G.x" indicators look like they should be divided by population.

### Correlations

Here we look at the associations between indicators, using correlations. Although correlations are a linear measure of dependence and relationships could be nonlinear, linear dependence still does a good job of flagging strong associations which we can later check more closely if required.

Let us begin with a general plot of all correlations between indicators to get an idea for the correlation structure. We exclude correlations between indicators that are not in the same dimension, and we draw boxes around each categoria. We also account for the *directions* of indicators, i.e. indicators with negative directionality have their directions reversed before calculating correlations.

```{r}
plot_corr(MVI, dset = "Denominated", showvals = FALSE, box_level = 2,
          grouplev = 3, flagcolours = TRUE, cortype = "spearman", pval = 0, use_directions = TRUE)
```

This shows that most correlations can be considered "OK" (correlation 0.3-0.9) or "weak" (correlation between -0.4 and 0.3). Obviously these thresholds are rough. In any case the main things to look out for are strongly negative correlations (which almost cancel out in aggregation) or collinearities (which can imply double counting). COINr has a dedicated function for picking these up:

```{r}
# any correlations above 0.9 within the same categoria
get_corr_flags(MVI, dset = "Denominated", cor_thresh = 0.9, thresh_type = "high",
               grouplev = 2, cortype = "spearman", use_directions = TRUE) |>
  knitr::kable(row.names = F)
```

Here we see that there is one instance of near-collinear relationships between indicators within the same categoria. In this case, these indicators would be flagged, such that they could be considered for removal. It is anyway a good idea to plot to see what is going on.

```{r}
#| warning: false
plot_scatter(MVI, dsets = "Denominated", iCodes = c("C.E.7", "C.E.8"))
```

We can see that the relationship here is very strongly linear, although there is also a degree of scatter.

We can do the same for negative correlations:

```{r}
# any negative correlations below -0.4 within the same categoria
get_corr_flags(MVI, dset = "Denominated", cor_thresh = -0.4, thresh_type = "low",
               grouplev = 2, cortype = "spearman", use_directions = TRUE) |>
  knitr::kable(row.names = F)
```

Here we see some fairly strong negative correlations. We will visualise some of these:

```{r}
#| warning: false
p1 <- plot_scatter(MVI, dsets = "Denominated", iCodes = c("S.A.3", "S.A.4"), log_scale = c(TRUE, TRUE))
p2 <- plot_scatter(MVI, dsets = "Denominated", iCodes = c("S.G.2", "S.G.4"), log_scale = c(TRUE, TRUE))

library(patchwork)
p1 + p2
```

The negative correlations here are only moderate and, although not ideal, this is not a strong case for removing any of these indicators unless there are additional reasons to do so.

## Conclusions

This analysis has checked:

* Data availability
* Zeroes and duplicates
* Outliers
* Presence of collinearity and/or strong negative correlations within groups

The objective being to see if indicators are *statistically* suitable for inclusion into the index. This makes no consideration of *conceptual* matters such as whether each indicator is relevant to the concept of vulnerability at the municipal level.

The main outcomes could be divided into "Red flags" and "Orange flags" (any indicators not mentioned are green-flagged). I would not normally use this kind of terminology but looking ahead to some kind of function that automatically flags indicators we could consider this approach. Or just have one flag category.

### Red flags

**Issue:** A.M.3 has a very low data availability at 12%

**Recommendation** Remove A.M.3 unless there is a very strong conceptual reason to keep it, or more data is expected to arrive soon.

### Orange flags

- **Issue:** A.M.1 has 75% of municipalities sharing the same value (zero). This means it is not very useful in sorting between municipalities.
  - **Recommendation:** This indicator could be removed on the above basis but could equally be kept if conceptually important.

- **Issue:** In total 27 indicators are flagged as having "outliers" based on skew and kurtosis thresholds. This can cause issues in aggregation if not treated.
  - **Recommendation:** Consider using outlier treatment methods for these indicators: in particular use log transformations to transform from log-normal to normal distributions. An alternative could be to use rank transformations. Both can be performed in COINr.

- **Issue:** Three indicator pairs were flagged as being close to collinear (C.I.5/C.I.6, S.A.2/S.A.3 and S.T.1/S.T.4).
  - **Recommendation:** Inspect each indicator pair to see whether there are any conceptual redundancies and whether any indicators could be removed.

- **Issue:** Eight pairs of indicators were flagged as having strong or moderately-strong negative correlations (after accounting for directionality). Indicators: "C.E.10/C.E.11", "C.E.10/C.E.9",  "C.E.8/C.E.9", "S.E.1/S.E.2", "S.E.2/S.E.3", "S.G.3/S.G.4", "S.G.3/S.G.6", "S.G.3/S.G.8".
  - **Recommendation:** Check the directionality of these indicators to see whether there are any mistakes. Check whether conceptually each indicator belongs to the correct aggregation group. In particular inspect the negative-collinear relationship of S.G.3 and S.G.8.
  
### Summary table

```{r}
source(here::here("R/old","selection.R"))

get_indicator_flags(MVI, "Denominated") |>
  knitr::kable(row.names = F)
```

