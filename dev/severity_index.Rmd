---
title: "Severity Index"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r development, include=FALSE}
library(testthat)

suppressMessages({
  library(readxl)
  library(COINr)
  library(plotly)
})

```

```{r development-load}
# Load already included functions if relevant
pkgload::load_all(export_all = FALSE)
```

# Introduction

This document introduces and documents the R code that was developed for the purposes of building a generalised "severity index" for the UNHCR in Guatemala. It also serves as the source code for a package based on this code which is built using the [fusen package](https://thinkr-open.github.io/fusen/index.html).

The work here began with the objective of building a severity index at the municipal level for Guatemala. However over the course of the project, the scope of the work expanded to aim for a generalised index framework which can be applied to other countries as well, with Guatemala serving as a case study or demo. Therefore the result here is a set of generalised code "modules" which can be used to build severity indexes for any set of user input data. In fact, the end objective is to use these code modules as the basis for an app which lets non-R-users build their own severity indexes from a GUI interface, probably using Shiny.

The code here consists of five "modules" which represent the basic steps expected by the user in building their own severity index. To summarise, they are:

1. Data input
2. Indicator analysis and selection
3. Index construction and visualisation
4. Reweighting
5. Export

Here, each module is summarised in a section of this documentation. The modules have a loose order of operation, with some subsequent modules requiring that the former are run first. For example, data input is mandatory and steps 2-5 cannot be run without it. However, indicator analysis and selection is optional - the following modules can still be run without it. Reweighting (4) cannot be run without index construction (3). Export can be enabled to run at any time, as long as data has been input.

Each module is organised as a collection of functions. Modules are expected to roughly correspond with "tabs" in an app, such that the user navigates from tab 1 (data input) through to tab 5 (export), following the order of operations. The dependence of one module on another can be managed in the app phase and according to the final specifications.

The code here rests heavily on the [COINr package](https://bluefoxr.github.io/COINr/) which is an R package for building and analysing composite indicators. The modules are built to act as a simplified interface between the user (via the app) and the COINr package. The idea is to guide the user to build their own severity index with a deliberately narrow range of options along the way. In this sense, the concept lies half way between a classical data exploration/visualisation of a single composite indicator (where the user can only explore an existing index) and a generalised GUI for building composite indicators (where a user might be able to build anything they want). This is a deliberate choice to enable an easy user interface.

As it stands, the code is loosely composed into an R package via the fusen package. Hence, all functions are defined here in the present R Markdown document. At the app building stage (if done via Shiny) it is expected to reorganise the code into a single Shiny-style R package.

For each module, a summary and general comments are given at the beginning of each section. Individual function description is given inside the function chunks themselves so that this is also viewable using `?function_name`.

Although unit tests are generated by the fusen package, the functions here are not thoroughly unit tested themselves due to time/scope constraints of the present phase. However, many are thinnish wrappers for COINr functions which are well-covered by [unit tests](https://github.com/bluefoxr/COINr/tree/master/tests/testthat).

All the main functions are covered by examples, although for helper functions (called by other functions) I have omitted the examples.

# DEMO DATA

The data set used to demonstrate the code package here is a set of 54 indicators covering 340 municipalities in Guatemala. This is found at `./inst/data_input/data_module-input.xlsx`. The input here is deliberately kept as an .xlsx file because that this the expected input from users. Here, we simply call up the file path of the example data. In the following section, the data will be read in.

```{r}
# Make your dataset file available to the current Rmd
pkgload::load_all(path = here::here(), export_all = FALSE)

# You will be able to read your example data file in each of your function examples and tests as follows
example <- system.file("data_input/data_module-input.xlsx", package = "BuildIndex") 
```

Note that the example data here does not represent a finished product in terms of the Guatemalan index: although the data set already went through a number of iterations, further adjustments may be made in terms of the selected indicators, index structure and possibly also the methodological choices. However, this represents a working data set for the purposes of this documentation.

# MODULE 1: DATA INPUT

**Objective**: To allow the user to input their data, which can then be used for the rest of the analysis.

**Input(s)**: File path pointing to an Excel spreadsheet with data in the format specified by the template.

**Output(s)**:

- Front end: confirmation of successful data entry, or else helpful error messages. Summary of what was input, e.g. number of indicators, number of units. An interactive framework plot and/or a table of data.
- Back end: An assembled coin.

This module consists of three functions:

* `f_data_input()` which reads the Excel spreadsheet and imports the data into R, and outputs a coin.
* `f_print_coin()` which prints a summary of the input data, to be output to the user.
* `f_plot_framework()` which outputs an interactive plot of the indicator framework.

The app is expected to be set up so that, on running `f_data_input()`, `f_print_coin()` and `f_plot_framework()` are automatically run to immediately show the user what they uploaded. The functions are documented in the following subsections (inside the roxygen2 metadata).

As mentioned previously, the code here is deliberately set up to only give limited options to the user. In the input file, the user has the option to define:

- Any number of indicators to include
- The indicator values for any number of units (municipalities or similar)
- Which "category" each indicator belongs to
- A short code and longer name for each indicator
- The directionality of each indicator (positive or negative)
- The initial weight to be assigned to each indicator
- Names for each municipality

The codes for each municipality must be the standardised "Admin 2" codes in order to be recognised in the mapping stage. In the app phase this check should be built in to the data input function.

Note that although the user can input their own data, the *structure* of the index is fixed and is defined by a data frame stored at `inst/data_input/iMeta_aggs.RDS`. This is "hard coded" into the data input function. Therefore, changing the structure, if needed, would amount to changing the stored data frame and altering the input template. Users can however decide which "categories" each indicator belongs to.

The input spreadsheet is still a work in progress and could be further optimised in the app phase. This would likely also entail adjusting `f_data_input()`.

## Data input
    
```{r function-f_data_input}
#' Data input
#' 
#' Reads a formatted Excel file found at `file_path` and outputs a constructed coin.
#' 
#' On reading the Excel file, this function does the following:
#' 
#' - Data is split into data and metadata and tidied
#' - Metadata is merged with hard-coded index structure
#' - Any indicators with no data at all are removed
#' - Any resulting aggregation groups with no "children" are removed
#' - A coin is assembled using COINr and this is the function output
#' 
#' If indicators/groups are removed, a message is sent to the console.
#' 
#' The Excel file is required to be in a fairly strict format: an example is given at
#' `inst/data_input/data_module-input.xlsx`. This template is still a work in progress
#' and can be modified in the app phase following further feedback. See also comments
#' in the main vignette.
#' 
#' @param file_path path to the excel file where we have the raw data - organised
#'      with the format expected by COINr package
#'      
#' @importFrom readxl read_excel  cell_limits 
#' @importFrom COINr new_coin   
#' 
#' @return coin-class object
#' 
#' @export
f_data_input <- function(file_path){
  
   # Settings ----

  # anchor points in spreadsheet
  idata_topleft <- c(5, 1)
  imeta_topleft <- c(1, 3)
  imeta_botleft <- c(5, 3)

  # col names to look for
  ucode_name <- "admin2Pcode"
  uname_name <- "Name"


  # Read in data ----

  iData <- readxl::read_excel(
    path = file_path, sheet = "Data",
    range = readxl::cell_limits(ul = idata_topleft, lr = c(NA, NA))
    )
  
  # Tidy iData ----

  names(iData)[names(iData) == ucode_name] <- "uCode"
  names(iData)[names(iData) == uname_name] <- "uName"
  
  # remove indicators with no data
  i_nodata <- names(iData)[colSums(!is.na(iData)) == 0]
  iData <- iData[!(names(iData) %in% i_nodata)]
  if(length(i_nodata) > 0){
    message("Removed indicators with no data points: ",
            paste0(i_nodata, collapse = ", "))
  }

  
  ## Read in metadata ----
  iMeta <- readxl::read_excel(
    path = file_path, sheet = "Data",
    range = readxl::cell_limits(ul = imeta_topleft,
                        lr = c(imeta_botleft[1], NA)),
    col_names = FALSE ) |> 
    suppressMessages()
  
  # Tidy and merge metadata ----
  iMeta <- as.data.frame(t(iMeta))
  names(iMeta) <- c("Weight", "Direction", "Parent", "iName", "iCode")
  iMeta$Weight <- as.numeric(iMeta$Weight)
  iMeta$Direction <- as.numeric(iMeta$Direction)
  row.names(iMeta) <- NULL

  # add cols (ready for merge)
  iMeta$Level <- 1
  iMeta$Type <- "Indicator"

  ## @will Maybe need to do some format checking
  ## Will: I agree, but this can only be done properly once the input template is finalised, so
  ## I think this has to be left for the app phase.
  # merge with aggregate levels
  
  ## @will - why not simply pulling this from the same excel ??
  ## Will: we don't want to give that flexibility/complexity to the user.
  ## OK! - - just puting it in for testing at the moment - 
  
  #  iMeta_aggs <- readRDS(here::here("inst/data_input", "iMeta_aggs.RDS"))
  #  iMeta_aggs <- readRDS(system.file("data_input/iMeta_aggs.RDS", package = "BuildIndex") )
  # write.csv( iMeta_aggs, here::here("inst", "iMeta_aggs.csv"), row.names = TRUE)
  
  ## Read in aggregation metadata ----
  iMeta_aggs <- readxl::read_excel( path = file_path, sheet = "iMeta_aggs") 
 
  iMeta <- rbind(iMeta, iMeta_aggs) |>
    #names(iMeta)
           dplyr::select( iCode,Parent, iName, Weight, Direction, Level, Type)
  
  # remove indicators metadata if there's no corresponding no data -
  # Aka level 1 -- cf cleaning above
  ## Should allow to avoid error "One or more entries in Parent not found in iCode" 
  iMeta <- iMeta[!(iMeta$iCode %in% i_nodata), ]

  # remove any second-level groups with no children
  no_children_1 <- iMeta$iCode[iMeta$Level == 2 & !(iMeta$iCode %in% iMeta$Parent)]
  iMeta <- iMeta[!(iMeta$iCode %in% no_children_1), ]
  if(length(no_children_1) > 0){
    message("Removed categories containing no indicators: ",
            paste0(no_children_1, collapse = ", "))
  }

  # remove any third-level groups with no children
  no_children_2 <- iMeta$iCode[iMeta$Level == 3 & !(iMeta$iCode %in% iMeta$Parent)]
  iMeta <- iMeta[!(iMeta$iCode %in% no_children_1), ]
  if(length(no_children_2) > 0){
    message("Removed dimensions containing no categories: ", no_children_2,
            paste0(no_children_2, collapse = ", "))
  }
  ## Catch issues on duplicated icode
  t <- as.data.frame(table(iMeta$iCode))  |>
       dplyr::filter(Freq > 1) |>
       dplyr::pull(Var1)
  if ( length(t) >0 ) { cat ( paste0(t, " is duplicated within your variable name. \n" ))} else {cat ()}


  # Build coin and output ----
  coin <- COINr::new_coin(iData, iMeta, quietly = FALSE,
           level_names = c("Indicator", "Category", "Dimension", "Index"))
  
  return(coin)
    
}
```
  
In the following, the example data is read in to create a coin called "MVI".

```{r example-f_data_input}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

```
  
```{r tests-f_data_input}
test_that("f_data_input works", {
  expect_true(inherits(f_data_input, "function")) 
})
```
  
  
## Print coin
    
```{r function-f_print_coin}
#' Print Coin
#' 
#' This is a print-style text output function for summarising the contents of the coin.
#' 
#' It is intended to be used immediately on loading data, to show the user what they have
#' input, so they can check for any unexpected things.
#'
#' @param coin The coin
#'
#' @return A coin
#' 
#'
#' @export

f_print_coin <- function(coin){

  cat("----------\n")
  cat("Your data:\n")
  cat("----------\n")
  # Input
  # Units
  firstunits <- paste0(utils::head(coin$Data$Raw$uCode, 3), collapse = ", ")
  if(length(coin$Data$Raw$uCode)>3){
    firstunits <- paste0(firstunits, ", ...")
  }

  # Indicators
  iCodes <- coin$Meta$Ind$iCode[coin$Meta$Ind$Type == "Indicator"]
  firstinds <- paste0(utils::head(iCodes, 3), collapse = ", ")
  if(length(iCodes)>3){
    firstinds <- paste0(firstinds, ", ...")
  }

  cat("Input:\n")
  cat("  Units: ", nrow(coin$Data$Raw), " (", firstunits, ")\n", sep = "")
  cat(paste0("  Indicators: ", length(iCodes), " (", firstinds, ")\n\n"))

  # Structure
  fwk <- coin$Meta$Lineage

  cat("Structure:\n")

  for(ii in 1:ncol(fwk)){

    codes <- unique(fwk[[ii]])
    nuniq <- length(codes)
    first3 <- utils::head(codes, 3)
    if(length(codes)>3){
      first3 <- paste0(first3, collapse = ", ")
      first3 <- paste0(first3, ", ...")
    } else {
      first3 <- paste0(first3, collapse = ", ")
    }

    # colnames are level names
    levnames <- colnames(fwk)
    # check if auto-generated, if so we don't additionally print.
    if(levnames[1] == "Level_1"){
      levnames <- NULL
    }

    if(ii==1){
      cat(paste0("  Level ", ii, " ", levnames[ii], ": ", nuniq, " indicators (", first3,") \n"))
    } else {
      cat(paste0("  Level ", ii, " ", levnames[ii], ": ", nuniq, " groups (", first3,") \n"))
    }

  }
  cat("\n")
    
}
```
  
The following example shows the output of this function:

```{r example-f_print_coin}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

f_print_coin(MVI)
```
  
```{r tests-f_print_coin}
test_that("f_print_coin works", {
  expect_true(inherits(f_print_coin, "function")) 
})
```
  
  
## Plot Framework
    
```{r function-f_plot_framework}
#' Interactive sunburst plot of index structure
#'
#' Plots the structure of the index using a sunburst plot using **plotly**.
#'
#' @param COIN coin object
#' @param seg_cols A character vector of colour codes, one for each segment in the plot. The length of this
#' vector must be equal to the number of segments, i.e. the sum of the number of indicators and aggregates
#' in each level. 
#' 
#' @importFrom plotly plot_ly
#' @importFrom COINr get_eff_weights
#' 
#' @return fig as a plotly plot
#' 
#' @export
f_plot_framework <- function(coin, seg_cols = NULL){

  # get iMeta
  iMeta <- coin$Meta$Ind

  # check if EffWeight present, if not, get
  if(is.null(iMeta$EffWeight)){
    coin <- COINr::get_eff_weights(coin, out2 = "coin")
    # get iMeta
    iMeta <- coin$Meta$Ind[!is.na(coin$Meta$Ind$Parent), ]
  }

  #iMeta$EffWeight <- round(iMeta$EffWeight, 2)

  if(is.null(seg_cols)){
    fig <- plotly::plot_ly(
      labels = iMeta$iCode,
      parents = iMeta$Parent,
      values = iMeta$EffWeight,
      type = 'sunburst',
      branchvalues = 'total',
      text = iMeta$iName,
      hoverinfo = 'text',
      texttemplate = '%{label}'
    )
  } else {
    stopifnot(is.vector(seg_cols),
              is.character(seg_cols))
    if(length(seg_cols) != length(outW$LabelsParents$Labels)){
      stop("seg_cols is the wrong length: it needs to be a character vector of colour codes that is
           the same length as the sum of all elements of the structure, in this case length should be ",
                  length(outW$LabelsParents$Labels))
    }
    fig <- plotly::plot_ly(
      labels = iMeta$iCode,
      parents = iMeta$Parent,
      values = iMeta$EffWeight,
      type = 'sunburst',
      branchvalues = 'total',
      marker = list(colors = seg_cols),
      text = iMeta$iName,
      hoverinfo = 'text',
      texttemplate = '%{label}'
    )
  }

  return(fig)
    
}
```
  
Run the following chunk to see the framework plot:

```{r example-f_plot_framework}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

f_plot_framework(MVI)
```
  
```{r tests-f_plot_framework}
test_that("f_plot_framework works", {
  expect_true(inherits(f_plot_framework, "function")) 
})
```
      

# MODULE 2: Indicator analysis and selection

**Objective**: To flag any statistical issues with indicators and allow the user to remove indicators if they want to (without having to edit their input file).

**Input(s)**: This is a two-stage process: the analysis and the indicator selection. For the former there is no input. For the latter the input will be any indicators to remove. In the code this is a vector of indicator codes, but in app it will be selected interactively.

**Output(s)**

- Front end: Analysis table at first step (as DT). Record of indicators removed.
- Back end: Analysis table as data frame, then modified coin after removal of indicators, if any.

This module aims to run an automated statistical analysis of the indicators input by the user, and flag any issues. Flags are generated for any indicators that have:

- Data availability below 66%
- More than half of the observations sharing the same value
- Possible outliers (absolute skew > 2 AND kurtosis > 3.5)
- Collinearity (correlation > 0.9) with any indicators within the same category
- Negative correlation (correlation < -0.4) with any indicators in the same category

The thresholds here are hard-coded into the function, since they are not expected to be accessible to the user, but can be adjusted by editing the source code.

The module consists of four main functions:

- `f_analyse_indicators()`: analyse indicators as described above
- `f_display_indicator_analysis()`: an interactive highlighted table displaying the results of the previous function
- `f_remove_indicators()`: remove specified indicator(s)
- `f_add_indicators()`: add specified indicator(s)

There are also several supporting functions. It is expected that the app will call `f_analyse_indicators()` and use  `f_display_indicator_analysis()` to display the results. The user will then have the possibility to remove or add back any indicators (flagged or otherwise) e.g. by selecting rows on the table, which will call `f_remove_indicators()` and `f_add_indicators()` on the back end.


## Analyse indicators
    
```{r function-f_analyse_indicators}
#' Analyse indicators 
#' 
#' Takes a coin and outputs an analysis of indicators. The objective is to look
#' for any "statistically-problematic" indicators, based on:
#' 
#' - data availability
#' - high proportion of repeated data values
#' - outliers as defined by skew and kurtosis
#' - collinearity within first aggregation level (category)
#' - negative correlation within first aggregation level (category)
#' 
#' The output can be viewed in R or as an interactive data frame.
#' Uses Spearman rank correlation to deal with skewed distributions.
#' Operates on the Raw data set.
#' 
#' The output is a coin with the results attached. This is so that on export, the
#' results will also be exported easily.
#' 
#' @param coin The coin
#' @param dat_avail_thresh default setting is  0.66,
#' @param skew_thresh default setting is  2,
#' @param kurt_thresh default setting is  3.5,
#' @param same_thresh default setting is  0.5,
#' @param collin_thresh default setting is  0.9,
#' @param neg_corr_thresh default setting is  -0.4
#' 
#' @return coin Updated coin with analysis tables
#' 
#' @importFrom COINr get_stats get_corr_flags is.coin
#' 
#' @export
f_analyse_indicators <- function(coin,
                                 dat_avail_thresh = 0.66,
                                 skew_thresh = 2,
                                 kurt_thresh = 3.5,
                                 same_thresh = 0.5,
                                 collin_thresh = 0.9,
                                 neg_corr_thresh = -0.4){

  stopifnot(COINr::is.coin(coin))

  # Settings ----

  # dat_avail_thresh <- 0.66
  # skew_thresh <- 2
  # kurt_thresh <- 3.5
  # same_thresh <- 0.5
  # collin_thresh <- 0.9
  # neg_corr_thresh <- -0.4

  # Univariate stats ----

  df_stats <- COINr::get_stats(
    coin, dset = "Raw",
    t_skew = skew_thresh,
    t_kurt = kurt_thresh,
    t_avail = dat_avail_thresh,
    out2 = "df")

  # prep df for display
  df_disp <- df_stats[c("iCode", "Frc.Avail", "Frc.Same")]
  # add skew and kurt
  df_disp$SkewKurt <- paste0(signif(df_stats$Skew, 3)," / ", signif(df_stats$Kurt, 3))

  # we find which iCodes are flagged for which things
  # prep a df
  df_flag <- data.frame(iCode = df_disp$iCode)

  # in the flag df TRUE means it is flagged as having a problem
  df_flag$Frc.Avail <- df_stats$Flag.Avail == "LOW"
  df_flag$Frc.Same <- df_stats$Frc.Same > 0.5
  df_flag$SkewKurt <- df_stats$Flag.SkewKurt == "OUT"

  # Bivariate (correlations) ----

  df_collinear <- COINr::get_corr_flags(
    coin, dset = "Raw",
    cor_thresh = collin_thresh,
    thresh_type = "high",
    grouplev = 2,
    cortype = "spearman",
    use_directions = TRUE)

  df_flag$Collinear <- df_flag$iCode %in% c(df_collinear$Ind1, df_collinear$Ind2)

  df_negcorr <- COINr::get_corr_flags(
    coin, dset = "Raw",
    cor_thresh = neg_corr_thresh,
    thresh_type = "low",
    grouplev = 2,
    cortype = "spearman",
    use_directions = TRUE)

  df_flag$NegCorr <- df_flag$iCode %in% c(df_negcorr$Ind1, df_negcorr$Ind2)

  # Tidy and output ----

  # assemble a big table for viewing (to probably adjust yet)
  df_disp <- df_disp[match(df_flag$iCode, df_disp$iCode), ]

  # add correlation entries

  pairs_colin <- f_gather_correlations(df_collinear)
  df_disp$Collinear <- pairs_colin[match(df_disp$iCode, names(pairs_colin))]

  pairs_neg <- f_gather_correlations(df_negcorr)
  df_disp$NegCorr <- pairs_neg[match(df_disp$iCode, names(pairs_neg))]

  # status column (will be changed if indicators are added/removed)
  df_disp$Status <- "In"
  df_flag$Status <- FALSE

  # add outputs to coin
  coin$Analysis$Raw <- list(
    FlaggedStats = df_disp,
    Flags = df_flag
  )

  return(coin)
}
```
  
```{r example-f_analyse_indicators}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )


MVI <- f_analyse_indicators(MVI)
```
  
```{r tests-f_analyse_indicators}
test_that("f_analyse_indicators works", {
  expect_true(inherits(f_analyse_indicators, "function")) 
})
```
  
## Gather correlations
    
```{r function-f_gather_correlations}
#' Gather correlations
#' 
#' Helper function for indicator analysis
#' 
#' @param X a frame with the 2 indicators to check `"Ind1"`  Ind1 &  `"Ind1"`
#' 
#' @return  nothing a report is created...
#' 
#' @export
f_gather_correlations <- function(X){

  Xpairs <- data.frame(v1 = c(X$Ind1, X$Ind2),
                       v2 = c(X$Ind2, X$Ind1))

  Xpairs <- Xpairs[order(Xpairs$v1, Xpairs$v2), ]

  tapply(Xpairs$v2, Xpairs$v1, paste0, collapse = ", ")
}
```
  
```{r example-f_gather_correlations}
#f_gather_correlations()
```
  
```{r tests-f_gather_correlations}
test_that("f_gather_correlations works", {
  expect_true(inherits(f_gather_correlations, "function")) 
})
```

## Display indicator analysis
    
```{r function-f_display_indicator_analysis}
#' Display indicator analysis
#' 
#' Displays the analysis performed by [f_analyse_indicators()] in an interactive
#' table using the DT package.
#' 
#' @param coin The coin.
#'              
#' @param  filter_to_flagged Logical: if `TRUE` filters to only show indicators with
#' at least one flag.
#' 
#' @importFrom COINr is.coin
#' @importFrom rlang abort
#' 
#' @return An interactive table (DT object).
#' 
#' @export
f_display_indicator_analysis <- function(coin, filter_to_flagged = TRUE){

  stopifnot(COINr::is.coin(coin))

  Xd <- coin$Analysis$Raw$FlaggedStats
  Xh <- coin$Analysis$Raw$Flags

  if(is.null(Xd) || is.null(Xh)){
    rlang::abort("Indicator analysis not found in coin. Run f_analyse_indicators() first.")
  }

  if(filter_to_flagged){

    # only include rows with at least one flag
    include_rows <- rowSums( Xh[!(names(Xh) %in% c("iCode", "Status"))] ) > 0

    Xd <- Xd[include_rows, ]
    Xh <- Xh[include_rows, ]

  }

  f_highlight_DT(Xd, Xh)
    
}
```
  
The following example generates the table:

```{r example-f_display_indicator_analysis}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

MVI <- f_analyse_indicators(MVI)

f_display_indicator_analysis(MVI)
```
  
```{r tests-f_display_indicator_analysis}
test_that("f_display_indicator_analysis works", {
  expect_true(inherits(f_display_indicator_analysis, "function")) 
})
```
  
  
## Highlight Data Table
    
```{r function-f_highlight_DT}
#' Highlight Data Table
#' 
#' Generic function for creating an interactive table with input df `Xd`, and
#' with cells highlighted by an equivalently sized logical df `Xh`.
#' This is used for displaying the output of `f_analyse_indicators()`.
#' 
#' @return A DT object
#' 
#' @export
f_highlight_DT <- function(Xd, 
                           Xh, 
                           table_caption = NULL, 
                           highlight_colour = "#ffc266"){

  stopifnot(identical(dim(Xd), dim(Xh)))

  ncol_display <- ncol(Xd)

  Xh_numeric <- lapply(Xh, function(x){
    if(is.logical(x)){
      as.numeric(x)
    } else {
      x
    }
  }) |> as.data.frame()

  X <- cbind(Xd, Xh_numeric)

  styles <- c("white", highlight_colour)

  DT::datatable(
    X,
    rownames = FALSE,
    caption = table_caption,
    options = list(
      columnDefs = list(
        list(
          visible=FALSE,
          targets=ncol_display:(ncol(X)-1)
        )
      )
    )
  ) |>
    DT::formatStyle(
      columns = 1:ncol_display,
      valueColumns = (ncol_display + 1):ncol(X),
      backgroundColor = DT::styleEqual(c(0,1), styles))
    
}
```
  
```{r example-f_highlight_DT}
#f_highlight_DT()
```
  
```{r tests-f_highlight_DT}
test_that("f_highlight_DT works", {
  expect_true(inherits(f_highlight_DT, "function")) 
})
```
  
## Remove indicators
    
```{r function-f_remove_indicators}
#' Remove indicators
#' 
#' Removes indicators as specified by a character vector of indicator
#' codes in `remove_indicators`. After removal, any results are regenerated
#' (updated).
#' 
#' The original data is always preserved so indicators can be restored.
#' Analysis tables are not currently re-run so this would have to be done separately.
#' However, there is actually no need to re-run.
#' 
#' @param coin A coin.
#' @param remove_indicators  Character vector of indicator codes to remove.
#' 
#' @importFrom COINr change_ind              
#' 
#' @return coin COIN object
#' 
#' @export
f_remove_indicators <- function(coin, 
                                remove_indicators = NULL){

  # extract analysis
  ind_analysis <- coin$Analysis$Raw
  analysis_exists <- !is.null(ind_analysis)

  coin <- COINr::change_ind(coin, drop = remove_indicators, regen = TRUE)

  if(analysis_exists){
    # edit and replace analysis
    ind_analysis$FlaggedStats$Status[
      ind_analysis$FlaggedStats$iCode %in% remove_indicators] <- "OUT"
    ind_analysis$Flags$Status[
      ind_analysis$Flags$iCode %in% remove_indicators] <- TRUE

    coin$Analysis$Raw <- ind_analysis
  }

  if(!is.null(coin$Data$Aggregated)){
    coin <- f_generate_results(coin)
  }

  return(coin)
    
}
```
  
The following example shows how indicators can be removed:

```{r example-f_remove_indicators}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

# call print method
MVI

MVI <- f_remove_indicators(MVI, c("S.G.3", "A.M.1"))
# compare with previous
MVI
```
  
```{r tests-f_remove_indicators}
test_that("f_remove_indicators works", {
  expect_true(inherits(f_remove_indicators, "function")) 
})
```
        
## Add indicators
    
```{r function-f_add_indicators}
#' Add indicators
#' 
#'  As `f_remove_indicators()` but adds indicators back in. Obviously only
#'  indicators that were originally present in the input data can be added.
#' 
#' @param coin The coin
#'              
#' @param add_indicators Character vector of indicator codes to add back in.
#'         
#' @importFrom COINr change_ind
#' 
#' @return coin Updated coin.
#' 
#' @export
f_add_indicators <- function(coin, add_indicators = NULL){

  # extract analysis
  ind_analysis <- coin$Analysis$Raw
  analysis_exists <- !is.null(ind_analysis)

  coin <- COINr::change_ind(coin, add = add_indicators, regen = TRUE)

  if(analysis_exists){
    # edit and replace analysis
    ind_analysis$FlaggedStats$Status[
      ind_analysis$FlaggedStats$iCode %in% add_indicators] <- "In"
    ind_analysis$Flags$Status[
      ind_analysis$Flags$iCode %in% add_indicators] <- FALSE

    coin$Analysis$Raw <- ind_analysis
  }

  if(!is.null(coin$Data$Aggregated)){
    coin <- f_generate_results(coin)
  }

  return(coin)

    
}
```
  
```{r example-f_add_indicators}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

# remove first
MVI <- f_remove_indicators(MVI, c("S.G.3", "A.M.1"))
# print method
MVI

# add one back
MVI <- f_add_indicators(MVI, "S.G.3")
MVI
```
  
```{r tests-f_add_indicators}
test_that("f_add_indicators works", {
  expect_true(inherits(f_add_indicators, "function")) 
})
```
  

# MODULE 3: Index construction and visualisation

**Objective**: To build the index from the indicators selected in the previous step and show the results as table/map/bar chart.

**Input(s)**: Possibly none from the user. If the methodology is fixed, there is no need for any input except perhaps which visualisation to use.

**Output(s)**

- Front end: Results table, bar chart, map
- Back end: Modified coin.

The index construction here uses the following steps:

1. Treat any outliers (this can be optional)
2. Normalise
3. Aggregate, using one of four currently-enabled methods.

Overall, the module consists of three main functions, plus some other helpers:

- `f_build_index()` which builds the index up the to the index level
- `f_display_results_table()` which outputs an interactive table of results
- `f_plot_map()` which plots a choropleth map of the index or any indicator/aggregate


## Benefit of doubt aggregation
    
```{r function-a_bod}
#' Benefit of doubt aggregation
#' 
#' As used in compind package. This is a wrapper which also returns `x` if `x`
#' only has one column (to avoid errors in Compind).
#' 
#' @param x A numeric vector
#' 
#' @export
a_bod <- function(x){
  if(ncol(x) == 1){
    return(x[[1]])
  }
  suppressMessages(Compind::ci_bod(x)$ci_bod_est)
}
```
  
```{r example-a_bod}
#
```
  
```{r tests-a_bod}
test_that("a_bod works", {
  expect_true(inherits(a_bod, "function")) 
})
```

  
## Wroclaw Taxonomic aggregation
    
```{r function-a_wroclaw}
#' Wroclaw Taxonomic aggregation
#' 
#' As used in Compind package. This is a wrapper which also returns `x` if `x`
#' only has one column (to avoid errors in Compind).
#' @param x A numeric vector
#' 
#' @export

a_wroclaw <- function(x){
  if(ncol(x) == 1){
    return(x[[1]])
  }
  suppressMessages(Compind::ci_wroclaw(x)$ci_wroclaw_est) |>
    as.numeric()
}
```
  
```{r example-a_wroclaw}
#
```
  
```{r tests-a_wroclaw}
test_that("a_wroclaw works", {
  expect_true(inherits(a_wroclaw, "function")) 
})
```
  

## Helper to get codes of any groups with only one child
    
```{r function-get_solo_groups}
#' Codes of any groups with only one child
#' 
#' To avoid errors in Compind functions
#' 
#' @param coin The coin
#' @export
#' 
#' @noRd
get_solo_groups <- function(coin){
  imeta <- coin$Meta$Ind
  parents <- imeta$Parent[!is.na(imeta$Parent)]
  x[which(!(duplicated(x) | duplicated(x, fromLast = TRUE)))]
}
```
  
```{r example-get_solo_groups}
#
```
  
```{r tests-get_solo_groups}
test_that("get_solo_groups works", {
  expect_true(inherits(get_solo_groups, "function")) 
})
```

## Build index
    
```{r function-f_build_index}
#' Build index
#' 
#' This function builds the index. It assumes that at this point you have imported
#' your data and built the coin. Also optionally you have analysed and
#' possibly removed indicators, but taken no further steps.
#' 
#' The operations performed here are:
#' 
#' - Treatment of outliers using a standard Winsorisation/log approach
#' - Normalistion to the 1, 100 interval
#' - Aggregation using one of the methods specified by `agg_method`
#' 
#' The output is an updated coin.
#' 
#' NOTE that for the Compind-powered aggregation methods, we need to be careful
#' about how the aggregated values are rescaled or not in the case of a single
#' indicator in an aggregation group. I initially blocked single-indicator groups
#' here but relaxed this after adjusting the aggregation wrapper functions.
#' 
#' @param coin The coin.
#' @param agg_method One of `"a_amean"` (arithmetic mean), `"a_gmean"` (geometric mean),
#' `"a_bod"` (benefit of doubt via Compind package) or `"a_wroclaw"` (Wroclaw Taxonomic Method via Compind).
#' @param max_winsorisation   default is 5,
#' @param skew_thresh default is  2,
#' @param kurt_thresh default is  3.5
#'              
#' @importFrom COINr is.coin qTreat Normalise Aggregate
#' 
#' @return coin Updated coin.
#' 
#' @export
f_build_index <- function(coin, 
                          agg_method = "a_amean",
                          max_winsorisation = 5,
                          skew_thresh = 2,
                          kurt_thresh = 3.5){

  stopifnot(COINr::is.coin(coin))
  
  # # If bod method, we can't proceed if any groups with only one child (throws error in compind)
  # if(agg_method %in% c("a_bod", "a_wroclaw")){
  #   solo_groups <- get_solo_groups(coin)
  #   if(length(solo_groups) > 1){
  #     rlang::abort(
  #       paste0(
  #         c("Cannot use benefit of doubt or Wroclaw methods because some framework groups have only one child: ", solo_groups),
  #         collapse = " "))
  #   }
  # }

  # Settings


  # treat outliers
  coin <- COINr::qTreat(coin, 
                        dset = "Raw",
                        winmax = max_winsorisation,
                        skew_thresh = skew_thresh,
                        kurt_thresh = kurt_thresh,
                        f2 = "log_CT_plus")

  # normalise to [1, 100]: otherwise if we have zeros can't use geometric mean
  coin <- COINr::Normalise(
    coin, 
    dset = "Treated",
    global_specs = list(f_n = "n_minmax",
                        f_n_para = list(l_u = c(1, 100)))
  )

  # AGGREGATE
  
  # some methods don't require weights input
  if(agg_method %in% c("a_bod", "a_wroclaw")){
    w <- "none"
    by_df <- TRUE
  } else {
    w <- NULL
    by_df <- FALSE
  }
  
  coin <- COINr::Aggregate(coin, dset = "Normalised", f_ag = agg_method, w = w, by_df = by_df)

  # generate results tables
  coin <- f_generate_results(coin)

  return(coin)
    
}
```
  
The example simply builds the index and writes to the coin.

```{r example-f_build_index}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

MVI1 <- f_build_index(coin = MVI, 
                     agg_method = "a_amean", #   (arithmetic mean),
                     max_winsorisation = 5,
                     skew_thresh = 2,
                     kurt_thresh = 3.5)

MVI2 <- f_build_index(coin = MVI, 
                     agg_method = "a_gmean", # (geometric mean),
                     max_winsorisation = 5,
                     skew_thresh = 2,
                     kurt_thresh = 3.5)

MVI3 <- f_build_index(coin = MVI, 
                     agg_method = "a_bod", # (benefit of doubt via Compind package) 
                     max_winsorisation = 5,
                     skew_thresh = 2,
                     kurt_thresh = 3.5)

MVI4 <- f_build_index(coin = MVI, 
                     agg_method = "a_wroclaw", # (Wroclaw Taxonomic Method via Compind)
                     max_winsorisation = 5,
                     skew_thresh = 2,
                     kurt_thresh = 3.5)
```
  
```{r tests-f_build_index}
test_that("f_build_index works", {
  expect_true(inherits(f_build_index, "function")) 
})
```
    

## Display results table
    
```{r function-f_display_results_table}
#' Display results table
#' 
#' Outputs an interactive results table suitable for HTML documents and the app.
#' Can be further formatted (e.g. conditional formatting) to preference in the 
#' app stage. This is just a demo.
#' 
#' @param coin The coin.
#' @param type set One of `"scores"` or `"ranks"`.
#' 
#' @importFrom rlang abort
#' @return An interactive table using DT.
#' 
#' @export
f_display_results_table <- function(coin, type = "scores"){

  if(type == "scores"){
    df_results <- coin$Results$FullScore
  } else if (type == "ranks"){
    df_results <- coin$Results$FullRank
  }

  if(is.null(df_results)){
    rlang::abort("Can't find results in the coin. Did you forget to build the index first?")
  }

  df_results |>
    DT::datatable(options = list(scrollX = TRUE), rownames = FALSE) |>
    DT::formatStyle(columns = ncol(df_results),
                fontSize = '50%')
    
}
```
  
```{r example-f_display_results_table}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

MVI <- f_build_index(MVI)
f_display_results_table(MVI)
```
  
```{r tests-f_display_results_table}
test_that("f_display_results_table works", {
  expect_true(inherits(f_display_results_table, "function")) 
})
```

## Plot map
    
```{r function-f_plot_map}
#' Plot map
#' 
#' Plots an interactive choropleth map of the index or any indicator, using 
#' supplied shape files. This is powered by the leaflet package.
#' 
#' Note we will need some checks here to make sure the shape file is compatible with the
#' data. This can be dealt with in the app phase.
#' 
#' @param coin The coin
#' @param dset Name of data set in the coin from which to extract the indicator/aggregate to plot
#' @param iCode Code of indicator within `"dset"` to plot
#' @param shp_path Assume a shapefile with `"ADM2_PCODE"` being the main key to use\
#'                with the default `"admin2Pcode"` within the indicator main excel file
#'                
#'                 Guatemala example is currently at `"./inst/shp/gtm_admbnda_adm2_ocha_conred_20190207.shp"`
#' 
#' @importFrom COINr get_data
#' @importFrom sf read_sf
#' @importFrom leaflet leaflet labelOptions highlightOptions addTiles addLegend
#' 
#' @return a leaflet object
#' 
#' @export
f_plot_map <- function(coin, 
                       dset = "Aggregated",
                       iCode = "MVI", 
                       shp_path){
  
  # read shape file
  shp <- sf::read_sf(shp_path)

  # get data first
  df_plot <- COINr::get_data(coin, dset = dset, iCodes = iCode)

  # merge into shape df
  shp$Indicator <- df_plot[[iCode]][match(shp$ADM2_PCODE, df_plot$uCode)]

  # colorBin is a leaflet function
  pal <- leaflet::colorBin("YlOrRd", domain = shp$Indicator, bins = 7)

  # labels
  labels <- sprintf(
    "<strong>%s</strong><br/>%g",
    shp$ADM2_ES, round(shp$Indicator, 1)
  ) |>
    lapply(htmltools::HTML)


  # now we can make the map

  mp <- leaflet::leaflet(shp) |>
    leaflet::addTiles() |>
    leaflet::addPolygons(
      fillColor = ~pal(Indicator),
      weight = 2,
      opacity = 1,
      color = "white",
      dashArray = "3",
      fillOpacity = 0.7,
      highlightOptions = leaflet::highlightOptions(
        weight = 5,
        color = "#666",
        dashArray = "",
        fillOpacity = 0.7,
        bringToFront = TRUE),
      label = labels,
      labelOptions = leaflet::labelOptions(
        style = list("font-weight" = "normal", padding = "3px 8px"),
        textsize = "15px",
        direction = "auto")) |>
    leaflet::addLegend(pal = pal, values = ~Indicator, opacity = 0.7, title = NULL,
              position = "bottomright")

  return(mp)
    
}
```
  
```{r example-f_plot_map}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

shp_path <-  system.file("data_input/gtm_admbnda_adm2_ocha_conred_20190207.shp",
                                            package = "BuildIndex")


MVI <- f_build_index(MVI)

f_plot_map(coin = MVI, 
           dset = "Aggregated",
           iCode = "MVI", 
           shp_path = shp_path  )
## when using ut your shape in the folder ---
         #  shp_path = here::here("inst/data-input", "gtm_admbnda_adm2_ocha_conred_20190207.shp")           )
```
  
```{r tests-f_plot_map}
test_that("f_plot_map works", {
  expect_true(inherits(f_plot_map, "function")) 
})
```


## Plot map v2
    
```{r function-f_plot_map2}
#' Plot map with main index and sub index
#' 
#' This second version of the summary map display the main severity index 
#'  together with all its sub-dimensions each them presented as selected layers
#'  
#' The infobox present the index (or subindex) value together with the rank 
#' 
#' Plots an interactive choropleth map using supplied shape files. The shapefile is 
#' automatically simplified so that the resulting html viz remains light
#' 
#' This is powered by the leaflet package.
#' 
#' Note we will need some checks here to make sure the shape file is compatible with the
#' data. This can be dealt with in the app phase.
#' 
#' @param coin The coin
#' 
#' @param dset Name of data set in the coin from which to extract the 
#'             indicator/aggregate to plot
#'             
#' @param shp_path Assume a shapefile matching  with ucode  
#'           Guatemala example is currently at
#'            `"./inst/shp/gtm_admbnda_adm2_ocha_conred_20190207.shp"`
#'            
#' @param shp_name  name of corresponding admin unit in the shapefile "ADM2_ES"
#' 
#' @param shp_ucode name of corresponding admincode matching  with ucode 
#'    in the shapefile  for instance `"ADM2_PCODE"` being the main key to use
#'                 
#'                 
#' @param dTolerance  1000 per default - parameter to simplify the shapefile so that the report is not too heavy... 
#' @param palette color palette for the map - selected as "inferno" per default to be inlusive of the 10% population of color blind people                 
#' 
#' @importFrom COINr get_data
#' @importFrom sf read_sf st_simplify
#' @importFrom leaflet leaflet labelOptions highlightOptions addTiles addLegend
#' @importFrom dplyr rename select  left_join
#' 
#' @return a leaflet object
#' 
#' @export
f_plot_map2 <- function(coin, 
                       dset = "Aggregated",
                       shp_path,
                       shp_name,
                       shp_ucode ,
                       dTolerance = 1000,
                       palette= "inferno"){
  
# read shape file
  shp0 <-sf::read_sf(shp_path) |>
         dplyr::rename("shp_name"= any_of(shp_name) ,
                        "shp_ucode"= any_of(shp_ucode)  ) |>
         dplyr::select(geometry, shp_name, shp_ucode)


  shp <-  sf::st_simplify(shp0,
                          preserveTopology = TRUE,
                          dTolerance = 1000)

  # cat( paste0("shape size reduction through simplification is ",round( as.numeric( object.size(shp0)-object.size(shp))/as.numeric(object.size(shp0))*100),0), "%\n")

 ## extract the top 2 level
  agg <- coin$Log$new_coin$iMeta |>
         dplyr::filter(Level %in% c( max(Level), max(Level)-1))
  # get data first with to level dimension
  df_plot <-  COINr::get_data(coin, dset = dset) |>
             dplyr::select(uCode, agg$iCode)

  ## Subset the select indic - plus all the one on the level below -
  # merge into shape df
  shp <- shp |>
         dplyr::left_join( df_plot , by = c( "shp_ucode"= "uCode"))
  
  # Add multiple layers with a loop 
  indexLayer <- agg$iCode
  splist <- list()
  labellist <- list()
  pallist <- list()
  for (thislayern in 1:length(indexLayer)) {
    thislayer <- indexLayer[thislayern]
    #cat( paste0(thislayer, "\n"))
    splist[[thislayern]] <- shp |>
      dplyr::select(geometry, any_of(thislayer), shp_name)
    
    labellist[[thislayern]] <-  sprintf(
      "<strong>%s</strong><br/>Index %s: %g<br/>Rank: %g / %g",
      splist[[thislayern]]$shp_name,
      as.character(thislayer),
      round(as.numeric(splist[[thislayern]][[thislayer]]), 1),
      rank(-  splist[[thislayern]][[thislayer]]),
      as.integer(nrow(splist[[thislayern]]))     ) |>
      lapply(htmltools::HTML)
    
    pallist[[thislayern]] <- leaflet::colorBin(palette= "inferno",
                             domain =  splist[[thislayern]][[thislayer]],
                             pretty = TRUE,
                             na.color = "#dbdbdb",
                             bins = 7)
  
  }
  library(leaflet)
    m <- leaflet::leaflet() |>
      leaflet::addProviderTiles(providers$Stamen.TonerLite, group = "Toner Lite")
    ## Add layers in a loop ----------------------------------
    for (thislayern in 1:length(indexLayer)) {
    # for (thislayern in 1:1) {
      thislayer <- indexLayer[thislayern]
       m <- m |>
          leaflet::addPolygons(
                          data = splist[[thislayern]],
                          group = thislayer,
                          fillColor = ~pallist[[thislayern]](splist[[thislayern]][[thislayer]]),
                          label = labellist[[thislayern]],
                          weight = 2,
                          opacity = 1,
                          color = "white",
                          dashArray = "2",
                          fillOpacity = 1,
                          highlightOptions = leaflet::highlightOptions(
                            weight = 5,
                            color = "#666",
                            dashArray = "",
                            fillOpacity = 0.7,
                            bringToFront = TRUE),
                          labelOptions = leaflet::labelOptions(
                            style = list("font-weight" = "normal", padding = "3px 8px"),
                            textsize = "15px",
                            direction = "auto"))   } # end of layers
    # Additional leaflet options ---------------------------------------------------
    m <- m |>
      # Add layers controls
      leaflet::addLayersControl(
        baseGroups = indexLayer,
        options = layersControlOptions(collapsed = FALSE)
      )
    # Add common legend
    # m <- m |>
    #   leaflet::addLegend(pal = pal,
    #                      values = ~ splist[[4]][[thislayer]],
    #                      opacity = 0.7,
    #                      title = NULL,
    #                      position = "bottomright")

  return(m)
    
}
```
  
```{r example-f_plot_map2}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

MVI <- f_build_index(MVI)

shp_path <-  system.file("data_input/gtm_admbnda_adm2_ocha_conred_20190207.shp",
                                            package = "BuildIndex")

shp_name <- "ADM2_ES"
shp_ucode <- "ADM2_PCODE"

f_plot_map2(coin = MVI, 
           dset = "Aggregated",
           shp_path = shp_path,
           shp_name = shp_name,
           shp_ucode = shp_ucode )
## when using ut your shape in the folder ---
         #  shp_path = here::here("inst/data-input", "gtm_admbnda_adm2_ocha_conred_20190207.shp")           )
```
  
```{r tests-f_plot_map2}
test_that("f_plot_map2 works", {
  expect_true(inherits(f_plot_map2, "function")) 
})
```
      
## Generate results
    
```{r function-f_generate_results}
#' Generate results
#' 
#' Generates sorted results tables and attaches back to the coin. This is a helper
#' function which is called by [f_build_index()].
#' 
#' @param coin The coin
#'              
#' @importFrom COINr is.coin get_results
#' 
#' @return Updated coin.
#' 
#' @export
f_generate_results <- function(coin){

  stopifnot(COINr::is.coin(coin),
            !is.null(coin$Data$Aggregated))

  # generate results tables (attached to coin, so will appear when exported to Excel)
  coin <- COINr::get_results(coin, dset = "Aggregated", tab_type = "Full",
                      also_get = "uName", nround = 1, out2 = "coin")
  coin <- COINr::get_results(coin, dset = "Aggregated", tab_type = "Full", use = "ranks",
                      also_get = "uName", nround = 1, out2 = "coin")

  return(coin)
    
}
```
  
```{r example-f_generate_results}
#
```
  
```{r tests-f_generate_results}
test_that("f_generate_results works", {
  expect_true(inherits(f_generate_results, "function")) 
})
```
  

# MODULE 4: Reweighting

**Objective**: To allow users to adjust weights manually to their preferences, and see the results interactively change.

**Input(s)**: Weights - which can be just at dimension level, or at dimension and category level. Would not recommend allowing indicator-level adjustment because it would result in a messy UI and probably confusion for the user.

**Output(s)**

- Front: No specific outputs in this module. We will use the outputs of the previous module, i.e. the map and table outputs.
- Back: Modified coin.

The idea here is to enable some interactive weight controls, such as sliders. The user adjusts the weights to their preference, and the results automatically update. This can probably be in the same "tab" as the results from the previous module, so on adjusting weights, the map or table will update.

As mentioned in discussions on this, allowing too much freedom with weight adjustment could lead to confusion or tuning weights to suit desired results. We could impose limits on weights, e.g. +/- 50%, which could help a bit here. This can be done by constraining the UI.

## Change weights
    
```{r function-f_change_weights}
#' Change weights
#' 
#' Function that takes some new weights and regenerates the coin. Results are
#' regenerated from the aggregation step only, so all previously-specified methodology
#' is fixed.
#' 
#'
#' @param coin The coin.
#' @param w weight. The weights `w` can either be a named list with names as iCodes
#'           and values the new weights, OR 
#'           as a data frame with columns "iCode" and "Weight" with 
#'           codes and corresponding weights.   
#'           In both cases a subset of weight-code pairs can be specified.
#'          E.g. `list("Salud" = 0.5, Amenazas = 0.8)`.
#' 
#'          OR set `w = "equal"` for equal weights everywhere, or `w = "original"` to use the
#'           weights that were input with the input data.
#' 
#'           Remember that weights are relative within aggregation groups.
#'                   
#' @importFrom COINr is.coin Regen
#' @importFrom rlang abort
#' 
#' @return Updated coin.
#' 
#' @export
f_change_weights <- function(coin, w){

  stopifnot(COINr::is.coin(coin))

  if(is.null(coin$Data$Aggregated)){
    rlang::abort("Can't find results in the coin. Did you forget to build the index first?")
  }

  # Get weights that were last used to aggregate ----

  # special case: reset or make equal
  if(is.character(w)){

    stopifnot(length(w) == 1)

    if(w == "equal"){
      w_new <- f_get_equal_weights(coin)
    } else if (w == "original"){
      w_new <- coin$Meta$Weights$Original
    }

    coin$Log$Aggregate$w <- w_new
    return(COINr::Regen(coin, from = "Aggregate"))
  }

  w_new <- f_get_last_weights(coin)

  # Alter weights based on input type ----

  if(is.data.frame(w)){

    stopifnot(all(c("iCode", "Weight") %in% names(w)),
              all(w$iCode %in% w_new$iCode),
              is.numeric(w$Weight))

    # subst new weights in
    w_new$Weight[match(w$iCode, w_new$iCode)] <- w$Weight

  } else if (is.list(w)){

    stopifnot(all(names(w) %in% w_new$iCode),
              all(sapply(w, is.numeric)),
              all(lengths(w) == 1))

    # subst new weights in
    w_new$Weight[match(names(w), w_new$iCode)] <- as.numeric(w)

  }

  # Regen with new weights ----

  coin$Log$Aggregate$w <- w_new

  # extract analysis
  ind_analysis <- coin$Analysis$Raw
  analysis_exists <- !is.null(ind_analysis)

  coin <- COINr::Regen(coin, from = "Aggregate")

  if(analysis_exists){
    coin$Analysis$Raw <- ind_analysis
  }

  # generate results tables again
  coin <- f_generate_results(coin)

  return(coin)
    
}
```
  
```{r example-f_change_weights}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

MVI <- f_build_index(MVI)
MVI2 <- f_change_weights(MVI, w= list(Amenazas = 1.5, Cap_Resp = 0.5))

# we can use a COINr function for a comparison
COINr::compare_coins(MVI, MVI2, dset = "Aggregated", iCode = "MVI") |>
  head()
```
  
```{r tests-f_change_weights}
test_that("f_change_weights works", {
  expect_true(inherits(f_change_weights, "function")) 
})
```
  
## Get equal weights
    
```{r function-f_get_equal_weights}
#' Get equal weights
#' 
#' Returns a weight data frame of equal weights. Helper called by [f_change_weights()].
#' 
#' @param coin The coin
#' 
#' @return A data frame of weights. 
#' 
#' @export
f_get_equal_weights <- function(coin){

  w <- coin$Meta$Weights$Original
  stopifnot(!is.null(w))

  w$Weight <- 1

  return(w)
    
}
```
  
```{r example-f_get_equal_weights}
#
```
  
```{r tests-f_get_equal_weights}
test_that("f_get_equal_weights works", {
  expect_true(inherits(f_get_equal_weights, "function")) 
})
```
  
  
## Get last weights
    
```{r function-f_get_last_weights}
#' Get last weights
#' 
#' Returns the data frame of weights last used to aggregate the coin. Helper
#' called by [f_change_weights()].
#' 
#' @param coin The coin
#' 
#' @return Data frame of weights.
#' 
#' @importFrom rlang abort
#' @export
f_get_last_weights <- function(coin){

  if(is.null(coin$Log$Aggregate)){
    return(NULL)
  }

  w_log <- coin$Log$Aggregate$w

  if(is.null(w_log)){

    w_new <- coin$Meta$Weights$Original

  } else if (is.character(w_log)){

    w_new <- coin$Meta$Weights[[w_log]]

  } else if (is.data.frame(w_log)){

    w_new <- w_log
  } else {
    rlang::abort("Weights not recognised at coin$Log$Aggregate$w")
  }

  stopifnot(is.data.frame(w_new))

  return(w_new)
    
}
```
  
```{r example-f_get_last_weights}
#
```
  
```{r tests-f_get_last_weights}
test_that("f_get_last_weights works", {
  expect_true(inherits(f_get_last_weights, "function")) 
})
```
      
      
# MODULE 5: Export


**Objective**: To export all results to Excel.

**Input(s)**: Just the command to export.

**Output(s)**

- Front end: An Excel spreadsheet with results.
- Back end: None

COINr has a function to export to Excel. However this outputs everything in the coin, which could be confusing to users and contains a lot of information that is probably not relevant. Instead, this module returns a simplified output which has the main results, a record of which indicators were selected, weights used, and the data sets generated at each construction stage for the record.

In more detail the output spreadsheet is as follows:

- Results table (scores)
- Results table (ranks)
- Index structure
- Analysis table (indicator analysis)
- Weights used
- Data sets generated at each stage

This module only consists of one function: `f_export_to_excel()`.

## Export to excel
    
```{r function-f_export_to_excel}
#' Export to excel
#' 
#' Simplified export to Excel with some formatting
#' Note if we change the index structure, the conditional formatting will need
#' to be adjusted.
#' 
#' 
#' @param coin The coin, with results present.
#' @param fname file name to write the results to.
#' 
#' @importFrom RColorBrewer brewer.pal
#' @importFrom openxlsx createWorkbook addWorksheet writeData writeDataTable
#'               conditionalFormatting saveWorkbook
#'               
#' @return Writes an Excel spreadsheet.
#' 
#' @export
f_export_to_excel <- function(coin, fname = "index_export.xlsx"){

  l <- list()

  # Results
  l$Scores <- coin$Results$FullScore
  l$Ranks <- coin$Results$FullRank

  # Structure
  l$Structure <- coin$Meta$Lineage

  # Analysis
  l$Analysis <- coin$Analysis$Raw$FlaggedStats

  # Weights
  l$Weights <- f_get_last_weights(coin)

  # Data sets
  l <- c(l, coin$Data)

  # colours
  tab_colours <- list(
    Results = "green",
    Structure = "orange",
    Analysis = "blue",
    Weights = "yellow",
    Other = "grey"
  )

  # Write
  wb <- openxlsx::createWorkbook()

  options("openxlsx.borderStyle" = "thin")
  options("openxlsx.borderColour" = "white")

  lapply(names(l), function(s){

    if(s %in% c("Scores", "Ranks")){

      openxlsx::addWorksheet(wb, s, tabColour = tab_colours[["Results"]])
      openxlsx::writeData(wb, sheet = s, x = l[[s]])
      openxlsx::writeDataTable(wb, s, x = l[[s]],
                     tableStyle = "TableStyleMedium6",
                     bandedRows = FALSE)

      r_format <- 2: (nrow(l[[s]]) + 1)

      if(s == "Scores"){

        # index score
        openxlsx::conditionalFormatting(
          wb, s, cols = 4, rows = r_format,
          type = "databar")

        # Mov_Hum
        # cols = c(5, 16)
        openxlsx::conditionalFormatting(
          wb, s, cols = 5, rows = r_format,
          style = RColorBrewer::brewer.pal(n = 3, name = "YlOrRd"),
          type = "colourScale")

        # Amenazas
        # c(6, 9, 10)
        openxlsx::conditionalFormatting(
          wb, s, cols = 6, rows = r_format,
          style = RColorBrewer::brewer.pal(n = 3, name = "RdPu"),
          type = "colourScale")

        # Sit_SocEc
        # c(7, 17:20)
        openxlsx::conditionalFormatting(
          wb, s, cols = 7, rows = r_format,
          style = RColorBrewer::brewer.pal(n = 3, name = "PuBuGn"),
          type = "colourScale")

        # Sit_SocEc
        # cols = c(8, 11:15)
        openxlsx::conditionalFormatting(
          wb, s, cols = 8, rows = r_format,
          style = RColorBrewer::brewer.pal(n = 3, name = "YlGnBu"),
          type = "colourScale")

      }

    } else if (s %in% c("Structure", "Analysis", "Weights")) {

      openxlsx::addWorksheet(wb, s, tabColour = tab_colours[[s]])
      openxlsx::writeData(wb, sheet = s, x = l[[s]])

    } else {

      openxlsx::addWorksheet(wb, s, tabColour = tab_colours[["Other"]])
      openxlsx::writeData(wb, sheet = s, x = l[[s]])
    }

  })

  # write to excel
  openxlsx::saveWorkbook(wb, fname, overwrite = TRUE)
}
```
  
```{r example-f_export_to_excel}
MVI <- f_data_input(file_path = system.file("data_input/data_module-input.xlsx",
                                            package = "BuildIndex") )

## when using create a data-raw folder and put you data input xlsx file there
# MVI <- f_data_input(here::here("data-raw", "data_module-input.xlsx"))
MVI <- f_analyse_indicators(MVI)
MVI <- f_build_index(MVI)

f_export_to_excel(coin = MVI, 
                  fname = here::here("inst", "index_export.xlsx"))
```
  
```{r tests-f_export_to_excel}
test_that("f_export_to_excel works", {
  expect_true(inherits(f_export_to_excel, "function")) 
})
```
  
## Generate technical report
    
```{r function-f_export_report}
# usethis::use_rmarkdown_template(
#   template_name = "Index_report",
#   template_dir = NULL,
#   template_description = "Index Review Report - html",
#   template_create_dir = TRUE
# )

#' Generate an html technical report
#' 
#' This functions provides a quick access to a basic report to generate severity index 
#' according multiple scenario
#' 
#' @param datafolder "data-raw" ## This is the default folder where to put you data in
#' @param data "data_module-input.xlsx" ## Name of the data file
#' @param shp "gtm_admbnda_adm2_ocha_conred_20190207.shp" ## name of the shapefile to create the map
#' @param folder folder within your project where to put the generated report. 
#' Folder will be created if it does not exist
#' 
#' @importFrom unhcrdown paged_simple
#' @importFrom dplyr filter select pull
#' @importFrom rmarkdown render
#' @importFrom here here
#' 
#' @return nothing the file for the report is generated
#' 
#' @export 
#'

f_export_report <- function(datafolder,
                            data,
                            shp,
                                   folder = "Report") {
  
  
    datafolder: "data-raw" ## This is the default folder where to put you data in
  data: "data_module-input.xlsx" ## Name of the data file
  shp: "gtm_admbnda_adm2_ocha_conred_20190207.shp" ## name of the shapefile to create the map
  
  ## Create the outfolder if it does not exist
  output_dir <- paste0(getwd(),"/",folder)
  if (!dir.exists(output_dir)) {dir.create(output_dir)}
   
  
  rmarkdown::render(
    system.file("rmarkdown/templates/index_report/skeleton/skeleton.Rmd", package = "BuildIndex"),
    output_file = here::here(folder, paste0('SeverityIndex_report-',   '.html') ),
    params = list(datafolder = datafolder,
                            data = data,
                            shp = shp)  )
}
  
```
  
```{r example-f_export_report}
# f_export_report(  datafolder = "data-raw", ## This is the default folder where to put you data in
#                   data = "data_module-input.xlsx", ## Name of the data file
#                  shp = "gtm_admbnda_adm2_ocha_conred_20190207.shp", ## name of the shapefile to create the map
#                  folder = "Report")
```
  
```{r tests-f_export_report}
test_that("f_export_report works", {
  expect_true(inherits(f_export_report, "function")) 
})
```
    
## Generate technical prez
    
```{r function-f_export_prez}
# usethis::use_rmarkdown_template(
#   template_name = "Index_prez",
#   template_dir = NULL,
#   template_description = "Index Review prez - html",
#   template_create_dir = TRUE
# ) 

#' Generate an html prez
#' 
#' This functions provides a quick access to a basic prez to generate severity index 
#' according multiple scenario
#' 
#' @param datafolder "data-raw" ## This is the default folder where to put you data in
#' @param data "data_module-input.xlsx" ## Name of the data file
#' @param shp "gtm_admbnda_adm2_ocha_conred_20190207.shp" ## name of the shapefile to create the map
#' @param folder folder within your project where to put the generated prez. 
#' Folder will be created if it does not exist
#' 
#' @importFrom unhcrdown paged_simple
#' @importFrom dplyr filter select pull
#' @importFrom rmarkdown render
#' @importFrom here here
#' 
#' @return nothing the file for the prez is generated
#' 
#' @export 
#'

f_export_prez <- function(datafolder,
                            data,
                            shp,
                                   folder = "Report") {
  
  
    datafolder: "data-raw" ## This is the default folder where to put you data in
  data: "data_module-input.xlsx" ## Name of the data file
  shp: "gtm_admbnda_adm2_ocha_conred_20190207.shp" ## name of the shapefile to create the map
  
  ## Create the outfolder if it does not exist
  output_dir <- paste0(getwd(),"/",folder)
  if (!dir.exists(output_dir)) {dir.create(output_dir)}
   
  
  rmarkdown::render(
    system.file("rmarkdown/templates/index_prez/skeleton/skeleton.Rmd", package = "BuildIndex"),
    output_file = here::here(folder, paste0('SeverityIndex_prez-',   '.html') ),
    params = list(datafolder = datafolder,
                            data = data,
                            shp = shp)  )
}
  
```
  
```{r example-f_export_prez}
# f_export_prez(  datafolder = "data-raw", ## This is the default folder where to put you data in
#                   data = "data_module-input.xlsx", ## Name of the data file
#                  shp = "gtm_admbnda_adm2_ocha_conred_20190207.shp", ## name of the shapefile to create the map
#                  folder = "Report")
```
  
```{r tests-f_export_prez}
test_that("f_export_prez works", {
  expect_true(inherits(f_export_prez, "function")) 
})
```  
  
  

```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "dev/severity_index.Rmd", vignette_name = "All functions", overwrite = 'yes', check = TRUE)
```

